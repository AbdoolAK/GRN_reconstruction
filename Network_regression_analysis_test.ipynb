{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f595be9c",
   "metadata": {},
   "source": [
    "# Network analysis - Ordinary Least Squares Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a371e5",
   "metadata": {},
   "source": [
    "**Context**\n",
    "\n",
    "This notebook loads in cell-type specifc Gene Regulatory Networks (GRNs) with the format: 'source' - 'target'. Where source refers to a Transcription Factor (TF) and target refers to a gene. The relationship i.e. row indicates that the TF under 'source' is targeting the gene under 'target' for activation of transcription. These celltype-specifc GRNs were created using the pipeline 'GRN_reconstruction_whole_data' by Abdool Al-Khaledi (a.g.al-khaledi@students.uu.nl). The pipeline takes as input a CellxGene Matrix and exports a file for each celltype containing the GRN in a 'source' - 'target' table format. This notebook carries out the subsequent part of the analysis: Modeling ASD activity as a function of total network activity and Time.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "The purpose of this notebook is to visualize ASD and GRN activity over time. As well model ASD activity as a function of GRN activity and time to regress out these variables on ASD regulon activity.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "The notebook begins by loading the GRN activity and ASD regulon activity. We quantify metrics for each time point including measures of GRN activity, ASD regulon activity and control TF activity. These metrics are then combined into 1 dataframe and melted into long format for the purpose of the regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro #test for normality\n",
    "from scipy.stats import mannwhitneyu #test significance between groups\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ASD genes \n",
    "os.chdir(\"/GRN_reconstruction/Mouse orthologues of SFARI genes/\")\n",
    "\n",
    "# Read csv containing gene names        \n",
    "autism_genes = pd.read_csv(\"autism_genes.csv\")\n",
    "\n",
    "# Locate genes with SFARI gene score of 1,2 or 3        \n",
    "autism_genes_1_2_3_df = pd.concat([autism_genes.loc[autism_genes['gene-score']==1], autism_genes.loc[autism_genes['gene-score']==2], autism_genes.loc[autism_genes['gene-score']==3]])\n",
    "\n",
    "# Create gene list\n",
    "autism_genes_1_2_3 = np.unique(np.unique(autism_genes_1_2_3_df['Mouse gene name']).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719a834",
   "metadata": {},
   "source": [
    "## Total GRN information ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total GRN activity for each timepoint.\n",
    "# Main directory\n",
    "main_dir = '' # Path to directory containing a subdirectory of networks. For example: 'parent_directory/' \n",
    "              # which can contain a subfolder for each time point (E10, E11, E12...etc)\n",
    "              # these subfolders should contain cell type-specific network dataframes.\n",
    "    \n",
    "# Create an empty dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over each subfolder in the main directory\n",
    "for subfolder in os.listdir(main_dir):\n",
    "\n",
    "    # Input directory - update the path to point to the current subfolder\n",
    "    input_dir = os.path.join(main_dir, subfolder)\n",
    "\n",
    "    # Create directories for ASD and non-ASD if they don't exist\n",
    "    ASD_output_dir = os.path.join(input_dir, 'ASD')\n",
    "    non_ASD_output_dir = os.path.join(input_dir, 'non_ASD')\n",
    "    if not os.path.exists(ASD_output_dir):\n",
    "        os.makedirs(ASD_output_dir)\n",
    "    if not os.path.exists(non_ASD_output_dir):\n",
    "        os.makedirs(non_ASD_output_dir)\n",
    "\n",
    "    # Reset lists to store results for each subfolder\n",
    "    filenames = []\n",
    "    GRN_activity_list = []\n",
    "    unique_ASD_TFs_list = []\n",
    "    free_floating_ASD_targets_list = []\n",
    "    ASD_Activity_list = []\n",
    "    ASD_genes_list = []\n",
    "    ASD_sources_list = []\n",
    "\n",
    "    # Your existing computations for GRN, ASD and non-ASD metrics go here, with modifications to account for subfolder-specific input and output directories\n",
    "    # Iterate over files in directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read network table\n",
    "            network_path = os.path.join(input_dir, filename)\n",
    "            network = pd.read_csv(network_path)\n",
    "\n",
    "            # Calculate GRN activity\n",
    "            GRN_activity = network.shape[0]\n",
    "\n",
    "            # Calculate number of unique ASD TFs in network\n",
    "            unique_ASD_TFs = len(set(network['source']).intersection(autism_genes_1_2_3))\n",
    "\n",
    "            # Calculate free-floating ASD targets\n",
    "            free_floating_ASD_targets = sum(network['target'].isin(autism_genes_1_2_3) & ~network['source'].isin(autism_genes_1_2_3))\n",
    "\n",
    "            # Calculate ASD genes count\n",
    "            ASD_genes_count = network['target'].isin(autism_genes_1_2_3).sum()\n",
    "            ASD_sources_count = network['source'].isin(autism_genes_1_2_3).sum()\n",
    "\n",
    "            # Count rows where either source or target is an ASD gene \"ASD edges\"\n",
    "            ASD_Activity = network[network['source'].isin(autism_genes_1_2_3) | network['target'].isin(autism_genes_1_2_3)].shape[0]\n",
    "\n",
    "            # Store results in lists\n",
    "            filenames.append(filename)\n",
    "            GRN_activity_list.append(GRN_activity)\n",
    "            unique_ASD_TFs_list.append(unique_ASD_TFs)\n",
    "            free_floating_ASD_targets_list.append(free_floating_ASD_targets)\n",
    "            ASD_Activity_list.append(ASD_Activity)\n",
    "            ASD_genes_list.append(ASD_genes_count)\n",
    "            ASD_sources_list.append(ASD_sources_count)\n",
    "    # After computing the metrics and storing them in lists, create the DataFrames for each subfolder\n",
    "\n",
    "    # GRN DataFrame\n",
    "    GRN_df = pd.DataFrame({\n",
    "        'Cell-type': filenames,\n",
    "        'GRN_Activity': GRN_activity_list,\n",
    "        'unique_ASD_TFs':unique_ASD_TFs_list,\n",
    "        'free_floating_ASD_targets':free_floating_ASD_targets_list,\n",
    "        'ASD_Activity':ASD_Activity_list,\n",
    "        'ASD_genes': ASD_genes_list,\n",
    "        'ASD_sources': ASD_sources_list\n",
    "    })\n",
    "\n",
    "    #Set index as celltype\n",
    "    GRN_df.set_index('Cell-type', inplace=True)\n",
    "\n",
    "    # Store the dataframe in the dictionary, using the subfolder name as the key\n",
    "    dfs[subfolder] = GRN_df\n",
    "\n",
    "# Now, to view the dataframes, you can do something like this:\n",
    "for key in dfs:\n",
    "    print(key)\n",
    "    display(dfs[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd86275",
   "metadata": {},
   "source": [
    "## Create ASD directory for each time-point ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each 'TimePeriod' subfolder in the main directory\n",
    "for time_period_folder in os.listdir(main_dir):\n",
    "    # Define the input directory within the current 'TimePeriod' subfolder\n",
    "    input_dir = os.path.join(main_dir, time_period_folder)\n",
    "\n",
    "    # Define the 'ASD' output subfolder within the current 'TimePeriod' subfolder\n",
    "    ASD_output_dir = os.path.join(main_dir, time_period_folder, 'ASD')\n",
    "\n",
    "    # Create 'ASD' output subfolder if it doesn't exist\n",
    "    if not os.path.exists(ASD_output_dir):\n",
    "        os.makedirs(ASD_output_dir)\n",
    "\n",
    "    # Loop over each CSV file (celltype-specifc network) in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read in the network\n",
    "            df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "            # Identify the subset of targets connected to ASD sources\n",
    "            asd_nodes = set(df[df['source'].isin(autism_genes_1_2_3)]['target'])\n",
    "        \n",
    "            # Identify the subset of targets connected to non-ASD sources\n",
    "            non_asd_nodes = set(df[~df['source'].isin(autism_genes_1_2_3)]['target'])\n",
    "        \n",
    "            # Identify the intersection of these target sets\n",
    "            overlapping_nodes = asd_nodes.intersection(non_asd_nodes)\n",
    "        \n",
    "            # If an ASD source is connected to a taget in overlapping_nodes, remove that interaction\n",
    "            df = df[~((df['source'].isin(autism_genes_1_2_3)) & (df['target'].isin(overlapping_nodes)))]\n",
    "\n",
    "            # Identify the targets unique to ASD TF sources\n",
    "            target_genes = set(df[df['source'].isin(autism_genes_1_2_3)]['target'])\n",
    "\n",
    "            # Identify rows where source is ASD TF and target is unique to ASD TF(s)\n",
    "            df = df[(df['source'].isin(autism_genes_1_2_3)) &  (df['target'].isin(target_genes))]\n",
    "\n",
    "            # Export the subsetted networks to output_dire\n",
    "            output_filename = os.path.join(ASD_output_dir, filename)\n",
    "            df.to_csv(output_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc90d0",
   "metadata": {},
   "source": [
    "## Populate created ASD folder with the ASD regulon subset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure ASD regulon activity.\n",
    "\n",
    "# Create a dictionary to store DataFrames for each 'TimePeriod' subfolder\n",
    "ASD_GRN_dfs = {}\n",
    "\n",
    "# Iterate over each 'TimePeriod' subfolder in the main directory\n",
    "for time_period_folder in os.listdir(main_dir):\n",
    "    # Define the 'ASD' subfolder within the current 'TimePeriod' subfolder\n",
    "    ASD_input_dir = os.path.join(main_dir, time_period_folder, 'ASD')\n",
    "\n",
    "    # Create empty lists to store results\n",
    "    filenames = []\n",
    "    ASD_GRN_activity_list = []\n",
    "\n",
    "    # Iterate over each CSV file in the 'ASD' subfolder\n",
    "    for filename in os.listdir(ASD_input_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read in the network\n",
    "            df = pd.read_csv(os.path.join(ASD_input_dir, filename))\n",
    "            \n",
    "            # Calculate ASD-GRN activity\n",
    "            ASD_GRN_activity = df.shape[0]\n",
    "        \n",
    "            # Store results in lists\n",
    "            filenames.append(filename)\n",
    "            ASD_GRN_activity_list.append(ASD_GRN_activity)\n",
    "\n",
    "    # Create a single dataframe \n",
    "    ASD_GRN_df = pd.DataFrame({\n",
    "        'name': filenames,\n",
    "        'ASD_GRN_activity': ASD_GRN_activity_list,\n",
    "    })\n",
    "\n",
    "    # Set index as celltype\n",
    "    ASD_GRN_df.set_index('name', inplace=True)\n",
    "\n",
    "    # Sort the values based on ASD_GRN_activity column\n",
    "    ASD_GRN_df = ASD_GRN_df.sort_values('ASD_GRN_activity', ascending=False)\n",
    "    \n",
    "    # Store DataFrame in the dictionary\n",
    "    ASD_GRN_dfs[time_period_folder] = ASD_GRN_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66409d29",
   "metadata": {},
   "source": [
    "## Create non_ASD directory in each time-point ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non_ASD subsets in each subfolder \n",
    "# Iterate over each 'TimePeriod' subfolder in the main directory\n",
    "for time_period_folder in os.listdir(main_dir):\n",
    "    # Define the input directory within the current 'TimePeriod' subfolder\n",
    "    input_dir = os.path.join(main_dir, time_period_folder)\n",
    "\n",
    "    # Define the 'ASD' output subfolder within the current 'TimePeriod' subfolder\n",
    "    non_ASD_output_dir = os.path.join(main_dir, time_period_folder, 'non_ASD')\n",
    "\n",
    "    # Create 'ASD' output subfolder if it doesn't exist\n",
    "    if not os.path.exists(non_ASD_output_dir):\n",
    "        os.makedirs(non_ASD_output_dir)\n",
    "\n",
    "    # Loop over each CSV file (celltype-specifc network) in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read in the network\n",
    "            df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "             # Identify the subset of targets connected to non-ASD sources\n",
    "            non_asd_nodes = set(df[~df['source'].isin(autism_genes_1_2_3)]['target'])\n",
    "        \n",
    "            # Identify the subset of targets connected to ASD sources\n",
    "            asd_nodes = set(df[df['source'].isin(autism_genes_1_2_3)]['target'])\n",
    "        \n",
    "            # Identify the intersection of these target sets\n",
    "            overlapping_nodes = non_asd_nodes.intersection(asd_nodes)\n",
    "        \n",
    "            # If a non-ASD source is connected to a target in overlapping_nodes, remove that interaction\n",
    "            df = df[~((~df['source'].isin(autism_genes_1_2_3)) & (df['target'].isin(overlapping_nodes)))]\n",
    "        \n",
    "            # Identify the targets unique to non-ASD TF sources\n",
    "            target_genes = set(df[~df['source'].isin(autism_genes_1_2_3)]['target'])\n",
    "        \n",
    "            # Identify rows where source is non-ASD TF and target is unique to non-ASD TF(s)\n",
    "            df = df[(~df['source'].isin(autism_genes_1_2_3)) &  (df['target'].isin(target_genes))]\n",
    "\n",
    "            # Export the subsetted networks to output_dir\n",
    "            output_filename = os.path.join(non_ASD_output_dir, filename)\n",
    "            df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7a61d",
   "metadata": {},
   "source": [
    "## Populate created non_ASD folder with the ASD regulon subset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9104f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store DataFrames for each 'TimePeriod' subfolder\n",
    "Ctrl_GRN_dfs = {}\n",
    "\n",
    "# Iterate over each 'TimePeriod' subfolder in the main directory\n",
    "for time_period_folder in os.listdir(main_dir):\n",
    "    # Define the 'ASD' subfolder within the current 'TimePeriod' subfolder\n",
    "    non_ASD_input_dir = os.path.join(main_dir, time_period_folder, 'non_ASD')\n",
    "\n",
    "    # Create empty lists to store results\n",
    "    filenames = []\n",
    "    Ctrl_GRN_activity_list = []\n",
    "\n",
    "    # Iterate over each CSV file in the 'ASD' subfolder\n",
    "    for filename in os.listdir(non_ASD_input_dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read in the network\n",
    "            df = pd.read_csv(os.path.join(non_ASD_input_dir, filename))\n",
    "            \n",
    "            # Calculate ctrl-GRN activity\n",
    "            CT_TF_activity = df.shape[0]\n",
    "        \n",
    "            # Store results in lists\n",
    "            filenames.append(filename)\n",
    "            Ctrl_GRN_activity_list.append(CT_TF_activity)\n",
    "\n",
    "    # Create a single dataframe \n",
    "    Ctrl_GRN_df = pd.DataFrame({\n",
    "        'name': filenames,\n",
    "        'Ctrl_GRN_activity': Ctrl_GRN_activity_list,\n",
    "    })\n",
    "\n",
    "    # Set index as celltype\n",
    "    Ctrl_GRN_df.set_index('name', inplace=True)\n",
    "\n",
    "    # Sort the values based on ASD_GRN_activity column\n",
    "    Ctrl_GRN_df = Ctrl_GRN_df.sort_values('Ctrl_GRN_activity', ascending=False)\n",
    "    \n",
    "    # Store DataFrame in the dictionary\n",
    "    Ctrl_GRN_dfs[time_period_folder] = Ctrl_GRN_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694f44b",
   "metadata": {},
   "source": [
    "## Combine the GRN, ASD regulon and control regulon information ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dictionary to store combined dataframes\n",
    "combined_dfs = {}\n",
    "\n",
    "# Iterate through keys of any dictionary (assuming all have the same keys)\n",
    "for key in dfs.keys():\n",
    "    # Join corresponding dataframes from each dictionary\n",
    "    combined_dfs[key] = dfs[key].join(Ctrl_GRN_dfs[key]).join(ASD_GRN_dfs[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, to view the dataframes, you can do something like this:\n",
    "for key in combined_dfs:\n",
    "    print(key)\n",
    "    display(combined_dfs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'GRN_Activity' from each DataFrame\n",
    "GRN_activity_dfs = {key: df['GRN_Activity'] for key, df in combined_dfs.items()}\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "GRN_activity_combined = pd.concat(GRN_activity_dfs, axis=1)\n",
    "\n",
    "# Calculate the average across all columns\n",
    "averages = GRN_activity_combined.mean(axis=1)\n",
    "\n",
    "# Sort the dataframe based on the average values in descending order\n",
    "GRN_activity_combined = GRN_activity_combined.loc[averages.sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d805533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "desired_order = ['E10', 'E11',... 'P4'] # Re-order based on data.\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "GRN_activity_combined = GRN_activity_combined.reindex(columns=desired_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_activity_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5107bcf",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set heatmap parameters\n",
    "cell_types = [os.path.splitext(os.path.basename(x))[0] for x in GRN_activity_combined.index]\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Draw heatmap with reduced font size for cell type labels and tick labels\n",
    "sns.heatmap(GRN_activity_combined, cmap='Spectral_r', annot=False, fmt='g', linewidths=.5, \n",
    "            cbar_kws={\"shrink\": .5}, yticklabels=cell_types)\n",
    "\n",
    "# Move xtick labels to top of heatmap\n",
    "plt.gca().xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "# Add x-axis label at top of graph\n",
    "plt.xlabel('')\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.gca().set_xlabel('Timepoint', fontsize=16)\n",
    "\n",
    "# Adjust font size of cell type labels and timepoint labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.ylabel('Cell Type', fontsize=16)\n",
    "\n",
    "# Reduce font size of cell type labels\n",
    "plt.yticks(fontsize=6)\n",
    "\n",
    "# Add color bar and title\n",
    "plt.title('Cell-Type GRN activity from E7 - E18', fontsize=20)\n",
    "\n",
    "\n",
    "# Save heatmap\n",
    "#plt.savefig('', dpi=300)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'ASD_sources' from each DataFrame\n",
    "ASD_sources_activity_dfs = {key: df['ASD_sources'] for key, df in combined_dfs.items()}\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "ASD_sources_activity_combined = pd.concat(ASD_sources_activity_dfs, axis=1)\n",
    "\n",
    "# Rename columns to include timepoint\n",
    "#GRN_activity_combined.columns = [f'{key} GRN_Activity' for key in GRN_activity_combined.columns]\n",
    "\n",
    "\n",
    "# Calculate the average across all columns\n",
    "averages = ASD_sources_activity_combined.mean(axis=1)\n",
    "\n",
    "# Sort the dataframe based on the average values in descending order\n",
    "ASD_sources_activity_combined = ASD_sources_activity_combined.loc[averages.sort_values(ascending=False).index]\n",
    "# Set heatmap parameters\n",
    "\n",
    "# Sort\n",
    "import pandas as pd\n",
    "\n",
    "# Define the desired column order\n",
    "desired_order = ['E10', 'E11', 'E12', 'E13', 'E14', 'E15',\n",
    "                 'E16', 'E17', 'E18', 'P1', 'P4']\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "ASD_sources_activity_combined = ASD_sources_activity_combined.reindex(columns=desired_order)\n",
    "\n",
    "\n",
    "cell_types = [os.path.splitext(os.path.basename(x))[0] for x in ASD_sources_activity_combined.index]\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Draw heatmap with reduced font size for cell type labels and tick labels\n",
    "sns.heatmap(ASD_sources_activity_combined, cmap='Spectral_r', annot=False, fmt='g', linewidths=.5, \n",
    "            cbar_kws={\"shrink\": .5}, yticklabels=cell_types)\n",
    "\n",
    "# Move xtick labels to top of heatmap\n",
    "plt.gca().xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "# Add x-axis label at top of graph\n",
    "plt.xlabel('')\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.gca().set_xlabel('Timepoint', fontsize=16)\n",
    "\n",
    "# Adjust font size of cell type labels and timepoint labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.ylabel('Cell Type', fontsize=16)\n",
    "\n",
    "# Reduce font size of cell type labels\n",
    "plt.yticks(fontsize=6)\n",
    "\n",
    "# Add color bar and title\n",
    "plt.title('Cell-Type ASD_sources_activity activity from E7 - E18', fontsize=20)\n",
    "\n",
    "\n",
    "# Save heatmap\n",
    "#plt.savefig('', dpi=300)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de11db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'ASD_GRN_activity' from each DataFrame\n",
    "ASD_GRN_activity_dfs = {key: df['ASD_GRN_activity'] for key, df in combined_dfs.items()}\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "ASD_GRN_activity_combined = pd.concat(ASD_GRN_activity_dfs, axis=1)\n",
    "\n",
    "# Rename columns to include timepoint\n",
    "#GRN_activity_combined.columns = [f'{key} GRN_Activity' for key in GRN_activity_combined.columns]\n",
    "\n",
    "\n",
    "# Calculate the average across all columns\n",
    "averages = ASD_GRN_activity_combined.mean(axis=1)\n",
    "\n",
    "# Sort the dataframe based on the average values in descending order\n",
    "ASD_GRN_activity_combined = ASD_GRN_activity_combined.loc[averages.sort_values(ascending=False).index]\n",
    "# Set heatmap parameters\n",
    "\n",
    "# Define the desired column order\n",
    "desired_order = ['E10', 'E11', 'E12', 'E13', 'E14', 'E15',\n",
    "                 'E16', 'E17', 'E18', 'P1', 'P4']\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "ASD_GRN_activity_combined = ASD_GRN_activity_combined.reindex(columns=desired_order)\n",
    "\n",
    "cell_types = [os.path.splitext(os.path.basename(x))[0] for x in ASD_GRN_activity_combined.index]\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Draw heatmap with reduced font size for cell type labels and tick labels\n",
    "sns.heatmap(ASD_GRN_activity_combined, cmap='Spectral_r', annot=False, fmt='g', linewidths=.5, \n",
    "            cbar_kws={\"shrink\": .5}, yticklabels=cell_types)\n",
    "\n",
    "# Move xtick labels to top of heatmap\n",
    "plt.gca().xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "# Add x-axis label at top of graph\n",
    "plt.xlabel('')\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.gca().set_xlabel('Timepoint', fontsize=16)\n",
    "\n",
    "# Adjust font size of cell type labels and timepoint labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.ylabel('Cell Type', fontsize=16)\n",
    "\n",
    "# Reduce font size of cell type labels\n",
    "plt.yticks(fontsize=6)\n",
    "\n",
    "# Add color bar and title\n",
    "plt.title('Cell-Type ASD_GRN_activity activity from E7 - E18', fontsize=20)\n",
    "\n",
    "\n",
    "# Save heatmap\n",
    "#plt.savefig('', dpi=300)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44423b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create an empty list to hold the legend patches\n",
    "patches = []\n",
    "\n",
    "# Iterate over each column in the DataFrame\n",
    "for column in ASD_GRN_activity_combined.columns:\n",
    "    # Select the column values\n",
    "    data = ASD_GRN_activity_combined[column].values.flatten()\n",
    "\n",
    "    # Filter out the non-zero values\n",
    "    data = data[data != 0]\n",
    "\n",
    "    # Create a histogram for the column\n",
    "    sns.histplot(data=data, kde=True)\n",
    "\n",
    "    # Get the color of the KDE line (which is darker than histogram)\n",
    "    line_color = plt.gca().lines[-1].get_color()\n",
    "\n",
    "    # Add a patch to the list for the legend\n",
    "    patches.append(mpatches.Patch(color=line_color, label=column))\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('ASD regulon activity', size =18)\n",
    "plt.ylabel('Number of cell types', size=18)\n",
    "plt.title('Distribution of ASD reuglon activities in cell types\\n accross developing mouse \"neo-cortex\"', size =24)\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(handles=patches)\n",
    "\n",
    "\n",
    "# Uncomment the following line if you want to save the plot\n",
    "#plt.savefig('', dpi=300)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d40fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'GRN_Activity' from each DataFrame\n",
    "CTRL_GRN_activity_dfs = {key: df['Ctrl_GRN_activity'] for key, df in combined_dfs.items()}\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "CTRL_GRN_activity_combined = pd.concat(CTRL_GRN_activity_dfs, axis=1)\n",
    "\n",
    "# Rename columns to include timepoint\n",
    "#GRN_activity_combined.columns = [f'{key} GRN_Activity' for key in GRN_activity_combined.columns]\n",
    "\n",
    "\n",
    "# Calculate the average across all columns\n",
    "averages = CTRL_GRN_activity_combined.mean(axis=1)\n",
    "\n",
    "# Sort the dataframe based on the average values in descending order\n",
    "CTRL_GRN_activity_combined = CTRL_GRN_activity_combined.loc[averages.sort_values(ascending=False).index]\n",
    "# Set heatmap parameters\n",
    "\n",
    "# Sort\n",
    "# Define the desired column order\n",
    "desired_order = ['E10', 'E11', 'E12', 'E13', 'E14', 'E15',\n",
    "                 'E16', 'E17', 'E18', 'P1', 'P4']\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "CTRL_GRN_activity_combined = CTRL_GRN_activity_combined.reindex(columns=desired_order)\n",
    "\n",
    "\n",
    "cell_types = [os.path.splitext(os.path.basename(x))[0] for x in CTRL_GRN_activity_combined.index]\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Draw heatmap with reduced font size for cell type labels and tick labels\n",
    "sns.heatmap(CTRL_GRN_activity_combined, cmap='Spectral_r', annot=False, fmt='g', linewidths=.5, \n",
    "            cbar_kws={\"shrink\": .5}, yticklabels=cell_types)\n",
    "\n",
    "# Move xtick labels to top of heatmap\n",
    "plt.gca().xaxis.set_ticks_position(\"top\")\n",
    "\n",
    "# Add x-axis label at top of graph\n",
    "plt.xlabel('')\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.gca().set_xlabel('Timepoint', fontsize=16)\n",
    "\n",
    "# Adjust font size of cell type labels and timepoint labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.ylabel('Cell Type', fontsize=16)\n",
    "\n",
    "# Reduce font size of cell type labels\n",
    "plt.yticks(fontsize=6)\n",
    "\n",
    "# Add color bar and title\n",
    "plt.title('Cell-Type CTRL_GRN_activity activity from E7 - E18', fontsize=20)\n",
    "\n",
    "\n",
    "# Save heatmap\n",
    "#plt.savefig('', dpi=300)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48f55b",
   "metadata": {},
   "source": [
    "## OLS regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d73650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape 'ASD_GRN_activity_combined' DataFrame from wide format to long format.\n",
    "# 'Cell-type' is kept as identifier variable.\n",
    "ASD_GRN_activity_long = ASD_GRN_activity_combined.reset_index().melt(id_vars='Cell-type', var_name='time', value_name='ASD_activity')\n",
    "\n",
    "# Reshape 'GRN_activity_combined' DataFrame from wide format to long format.\n",
    "# 'Cell-type' is kept as identifier variable.\n",
    "GRN_activity_long = GRN_activity_combined.reset_index().melt(id_vars='Cell-type', var_name='time', value_name='GRN_activity')\n",
    "\n",
    "# Merge the two reshaped dataframes on 'Cell-type' and 'time' columns.\n",
    "# 'left' merge is used, so all rows from the first (left) dataframe and only the matched rows from the second (right) dataframe will be returned.\n",
    "df = pd.merge(ASD_GRN_activity_long, GRN_activity_long,  how='left', left_on=['Cell-type','time'], right_on = ['Cell-type','time'])\n",
    "\n",
    "# Define the order of the time stages\n",
    "column_order = ['E10', 'E11', 'E12', 'E13', 'E14', 'E15','E16', 'E17', 'E18', 'P1', 'P4']\n",
    "\n",
    "# Map the time stages to a numerical value for use in regression\n",
    "time_dict = {col: i+1 for i, col in enumerate(column_order)}\n",
    "df['time'] = df['time'].map(time_dict)\n",
    "\n",
    "# Specify the Ordinary Least Squares (OLS) model.\n",
    "# The model will regress 'ASD_activity' on 'GRN_activity' and 'time'.\n",
    "model = smf.ols(formula='ASD_activity ~ GRN_activity + time', data=df)\n",
    "\n",
    "# Fit the model using robust covariance estimation method 'HC3'.\n",
    "# This method provides a robust standard errors in the case of heteroscedasticity.\n",
    "results = model.fit(cov_type='HC3')\n",
    "\n",
    "# Get the residuals from the model.\n",
    "residuals = results.resid\n",
    "\n",
    "# Printing the summary statistics of the model.\n",
    "print(results.summary())\n",
    "\n",
    "# Adding the residuals to the dataframe.\n",
    "df['residuals'] = results.resid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eadbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert time-point dictionary\n",
    "inverse_time_dict = {v: k for k, v in time_dict.items()}\n",
    "df['time'] = df['time'].map(inverse_time_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84ed99",
   "metadata": {},
   "source": [
    "Investigate fit and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6c83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the histogram of residuals\n",
    "plt.hist(residuals, bins='auto', density=False, alpha=0.7)\n",
    "plt.xlabel('Residual value', size=12)\n",
    "plt.ylabel('Number of residuals', size=12)\n",
    "plt.title('Histogram of residuals', size=16)\n",
    "#plt.savefig('', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the Q-Q plot of residuals\n",
    "qqplot = stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.xlabel('Theoretical quantiles', size=12)\n",
    "plt.ylabel('Sample quantiles', size=12)\n",
    "plt.title('Q-Q plot of residuals', size=16)\n",
    "#plt.savefig('', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Perform the Shapiro-Wilk test for normality\n",
    "_, p_value = stats.shapiro(residuals)\n",
    "# Calculate the mean of residuals\n",
    "residual_mean = residuals.mean()\n",
    "print(\"Mean of residuals:\", residual_mean)\n",
    "\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-value is above the significance level\n",
    "if p_value > alpha:\n",
    "    print(\"Residuals are normally distributed (according to the Shapiro-Wilk test).\")\n",
    "else:\n",
    "    print(\"Residuals are not normally distributed (according to the Shapiro-Wilk test).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec275d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add residuals to original DataFrame\n",
    "df['residuals'] = residuals\n",
    "\n",
    "# Sort the DataFrame by residuals\n",
    "df_sorted_by_residuals = df.sort_values(by='residuals')\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Enable scrolling\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Convert DataFrame to HTML and set a CSS property to make the table scrollable\n",
    "df_html = df_sorted_by_residuals.to_html()\n",
    "styled_df_html = '<style> .dataframe {height: 400px; overflow-y: auto;}</style>' + df_html\n",
    "\n",
    "# Display HTML\n",
    "display(HTML(styled_df_html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7a810",
   "metadata": {},
   "source": [
    "Visualize ASD regulon activity as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted values\n",
    "df['predicted_ASD_activity'] = results.fittedvalues\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual ASD activity\n",
    "sns.lineplot(x=df['time'], y=df['ASD_activity'], label='Actual ASD regulon activity')\n",
    "\n",
    "# Plot predicted ASD activity (GRN activity held constant)\n",
    "sns.lineplot(x=df['time'], y=df['predicted_ASD_activity'], label='Predicted ASD regulon activity')\n",
    "\n",
    "plt.title('Predicted Vs. Actual average ASD regulon activity\\n over mouse neo-cortex development', size =22)\n",
    "plt.xlabel('Time', size=12)\n",
    "plt.ylabel('ASD regulon activity', size=12)\n",
    "plt.legend()\n",
    "# Move legend to the left of the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(0., 0.7))\n",
    "plt.savefig('', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual ASD activity\n",
    "plt.scatter(df['time'], df['ASD_activity'], label='Actual ASD regulon activity')\n",
    "\n",
    "# Plot predicted ASD activity\n",
    "plt.scatter(df['time'], df['predicted_ASD_activity'], label='Predicted ASD regulon activity')\n",
    "\n",
    "plt.title('Predicted Vs. Actual ASD regulon activity\\n over mouse neo-cortex development', size =24)\n",
    "plt.xlabel('Time', size=16)\n",
    "plt.ylabel('ASD regulon activity', size=16)\n",
    "plt.legend()\n",
    "\n",
    "# Uncomment the following line if you want to save the plot\n",
    "plt.savefig('', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cacf387",
   "metadata": {},
   "source": [
    "## END "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
